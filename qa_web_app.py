# ğŸ“‹ ê²Œì‹œíŒ ìƒë‹´ QA í‰ê°€ ì›¹ì•± (ì•ˆì •í˜•: í‰ê°€ í•­ëª© ì¶•ì†Œ + ê±´ìˆ˜ ì œí•œ + timeout ì„¤ì •)

import streamlit as st
import openai
import os
from dotenv import load_dotenv
import pandas as pd
import io

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ğŸ§¾ ì›¹ì•± ì„¤ì •
st.set_page_config(page_title="ê²Œì‹œíŒ QA ìë™ í‰ê°€ê¸°", page_icon="ğŸ“")
st.title("ğŸ“‹ ê²Œì‹œíŒ QA ìë™ í‰ê°€ê¸°")

st.markdown("""
ì´ ì›¹ì•±ì€ ê³ ê° ì§ˆë¬¸ê³¼ ìƒë‹´ì‚¬ ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ GPT ëª¨ë¸ì„ í™œìš©í•´ QA í‰ê°€ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- ë‹¨ê±´ ì…ë ¥ ë˜ëŠ” ë‹¤ê±´ ì—…ë¡œë“œ(CSV) í›„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- âš  ë‹¤ê±´ í‰ê°€ëŠ” ìµœëŒ€ 10ê±´ê¹Œì§€ë§Œ í‰ê°€ë©ë‹ˆë‹¤.
""")

# ğŸ”¹ ë‹¨ê±´ ì…ë ¥ ì˜ì—­
st.subheader("âœ ë‹¨ê±´ QA í‰ê°€")
customer = st.text_area("ê³ ê° ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", height=120)
agent = st.text_area("ìƒë‹´ì‚¬ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”:", height=150)

if st.button("ğŸ§  ë‹¨ê±´ QA í‰ê°€ ì‹¤í–‰"):
    if not customer or not agent:
        st.warning("ê³ ê° ì§ˆë¬¸ê³¼ ìƒë‹´ì‚¬ ë‹µë³€ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("GPTê°€ ë‹¨ê±´ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
            prompt = f"""
ë„ˆëŠ” ê³ ê°ì„¼í„° QA í‰ê°€ ì „ë¬¸ê°€ì•¼.

[ê³ ê° ì§ˆë¬¸]
{customer}

[ìƒë‹´ì‚¬ ë‹µë³€]
{agent}

[í‰ê°€ í•­ëª©]
1. ë¬¸ì œ íŒŒì•… â€“ ê³ ê° ì˜ë„ë¥¼ ì •í™•íˆ ì´í•´í–ˆëŠ”ê°€?
2. ì‘ë‹µ ì •í™•ë„ â€“ ì •ë³´ ê¸°ì¤€ì— ë§ëŠ” ì •í™•í•œ ë‹µë³€ì¸ê°€?
3. ê³µê° í‘œí˜„ â€“ ì •ì¤‘í•˜ê³  ê³µê° ì–´ë¦° í‘œí˜„ì´ ìˆì—ˆëŠ”ê°€?
4. í•´ê²°ì±… ì œì‹œ â€“ ê³ ê° ë¬¸ì œ í•´ê²° ë°©í–¥ì„ ì œì‹œí–ˆëŠ”ê°€?
5. ì „ë°˜ì  ì¸ìƒ â€“ ì„±ì˜ì™€ ì•ˆì •ê°ì´ ëŠê»´ì¡ŒëŠ”ê°€?

**ê° í•­ëª©ì— ëŒ€í•´ ì ìˆ˜(10ì  ë§Œì )ì™€ ê°„ë‹¨í•œ ì½”ë©˜íŠ¸ë¥¼ í…Œì´ë¸”ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì¤˜.**
            """
            try:
                response = openai.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.4,
                    max_tokens=800,
                    timeout=60
                )
                result = response.choices[0].message.content.strip()
                st.markdown("### ğŸ“ ë‹¨ê±´ í‰ê°€ ê²°ê³¼")
                st.markdown(result)
            except Exception as e:
                st.error(f"âŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ğŸ”¹ ë‹¤ê±´ í‰ê°€ ì˜ì—­ ë³µì›
st.subheader("ğŸ“ ë‹¤ê±´ QA í‰ê°€ (CSV ì—…ë¡œë“œ, ìµœëŒ€ 10ê±´)")
uploaded_file = st.file_uploader("ê³ ê° ì§ˆë¬¸/ìƒë‹´ì‚¬ ë‹µë³€ CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    if 'ê³ ê°ì§ˆë¬¸' not in df.columns or 'ìƒë‹´ì‚¬ë‹µë³€' not in df.columns:
        st.error("CSVì—ëŠ” ë°˜ë“œì‹œ 'ê³ ê°ì§ˆë¬¸', 'ìƒë‹´ì‚¬ë‹µë³€' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
    elif st.button("ğŸ§  ë‹¤ê±´ í‰ê°€ ì‹¤í–‰"):
        df = df.head(10)
        results = []
        from time import sleep
        progress_bar = st.progress(0, text="ğŸ”„ GPT ë‹¤ê±´ í‰ê°€ ì§„í–‰ ì¤‘...")
        total = len(df)

        for i, (idx, row) in enumerate(df.iterrows()):
            prompt = f"""
ë„ˆëŠ” ê³ ê°ì„¼í„° QA í‰ê°€ ì „ë¬¸ê°€ì•¼.

ì•„ë˜ ê³ ê° ì§ˆë¬¸ê³¼ ìƒë‹´ì‚¬ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ 5ê°€ì§€ í•­ëª©ì— ëŒ€í•´ ì ìˆ˜(10ì  ë§Œì )ì™€ ì§§ì€ ì½”ë©˜íŠ¸ë¥¼ ì‘ì„±í•˜ê³ ,
ë‹¤ìŒê³¼ ê°™ì€ **í…Œì´ë¸” í˜•ì‹**ìœ¼ë¡œ ì¶œë ¥í•´ì¤˜:

í˜•ì‹:
| í•­ëª© | ì ìˆ˜ | ê²°ê³¼ ìš”ì•½ |
|------|------|-------------|
| 1. ë¬¸ì œ íŒŒì•… | 8ì  | ê³ ê°ì˜ ìš”ì²­ì€ ì´í•´í–ˆì§€ë§Œ íšŒìˆ˜ í™•ì¸ ë°©ì‹ì€ ë¹ ì¡ŒìŒ |
...

ë§ˆì§€ë§‰ì—ëŠ” ì´ì ë„ ë”°ë¡œ ì¶œë ¥í•´ì¤˜.

[ê³ ê° ì§ˆë¬¸]
{row['ê³ ê°ì§ˆë¬¸']}

[ìƒë‹´ì‚¬ ë‹µë³€]
{row['ìƒë‹´ì‚¬ë‹µë³€']}

[í‰ê°€ í•­ëª©]
1. ë¬¸ì œ íŒŒì•… â€“ ê³ ê° ì˜ë„ë¥¼ ì •í™•íˆ ì´í•´í–ˆëŠ”ê°€?
2. ì‘ë‹µ ì •í™•ë„ â€“ ì •ë³´ ê¸°ì¤€ì— ë§ëŠ” ì •í™•í•œ ë‹µë³€ì¸ê°€?
3. ê³µê° í‘œí˜„ â€“ ì •ì¤‘í•˜ê³  ê³µê° ì–´ë¦° í‘œí˜„ì´ ìˆì—ˆëŠ”ê°€?
4. í•´ê²°ì±… ì œì‹œ â€“ ê³ ê° ë¬¸ì œ í•´ê²° ë°©í–¥ì„ ì œì‹œí–ˆëŠ”ê°€?
5. ì „ë°˜ì  ì¸ìƒ â€“ ì„±ì˜ì™€ ì•ˆì •ê°ì´ ëŠê»´ì¡ŒëŠ”ê°€?

**ê¼­ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì¤˜.**
"""
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.4,
                    max_tokens=800,
                    timeout=60
                )
                results.append(response.choices[0].message.content.strip())
                progress_bar.progress((i + 1) / total, text=f"âœ… {i + 1}/{total} ê±´ ì™„ë£Œ")
            except Exception as e:
                results.append(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
                progress_bar.progress((i + 1) / total, text=f"âš  {i + 1}/{total} ê±´ ì˜¤ë¥˜")

        df["GPTí‰ê°€ê²°ê³¼"] = results
        st.success(f"ì´ {len(df)}ê±´ í‰ê°€ ì™„ë£Œ!")

        # ğŸ“Š í†µê³„ ë° ê²°ê³¼ êµ¬ì¡°í™”
        parsed_rows = []
        avg_scores = []
        for idx, result in enumerate(results):
            try:
                lines = result.split("\n")
                current_question = df.loc[idx, "ê³ ê°ì§ˆë¬¸"]
                current_answer = df.loc[idx, "ìƒë‹´ì‚¬ë‹µë³€"]

                for line in lines:
                    if line.strip().startswith("|") and line.count("|") >= 4:
                        parts = [cell.strip() for cell in line.strip().split("|")[1:-1]]
                        if len(parts) == 3:
                            í•­ëª©, ì ìˆ˜, ìš”ì•½ = parts
                            parsed_rows.append({
                                "ê³ ê°ì§ˆë¬¸": current_question,
                                "ìƒë‹´ì‚¬ë‹µë³€": current_answer,
                                "í•­ëª©": í•­ëª©,
                                "ì ìˆ˜": ì ìˆ˜,
                                "ê²°ê³¼ ìš”ì•½": ìš”ì•½
                            })
                    elif "ì´ì " in line:
                        total = ''.join([c for c in line if c.isdigit()])
                        avg_scores.append(int(total))
                        parsed_rows.append({
                            "ê³ ê°ì§ˆë¬¸": current_question,
                            "ìƒë‹´ì‚¬ë‹µë³€": current_answer,
                            "í•­ëª©": "ì´ì ",
                            "ì ìˆ˜": total + "ì ",
                            "ê²°ê³¼ ìš”ì•½": ""
                        })
            except Exception as e:
                st.warning(f"âš  ê²°ê³¼ íŒŒì‹± ì˜¤ë¥˜: {e}")

        result_df = pd.DataFrame(parsed_rows)

        if avg_scores:
            avg = sum(avg_scores) / len(avg_scores)
            st.metric("ğŸ“ˆ í‰ê·  ì´ì ", f"{avg:.1f}ì ")

        st.caption("â± ê° ê±´ í‰ê°€ì—ëŠ” ì•½ 5~10ì´ˆ ì†Œìš”ë©ë‹ˆë‹¤.")

        # ğŸ‘‰ ì „ì²´ ê²°ê³¼ í…Œì´ë¸” ì‹œê°í™” ì œê±°ë¨

        csv_structured = result_df.to_csv(index=False).encode('utf-8-sig')
        csv_raw = df.to_csv(index=False).encode('utf-8-sig')

        st.download_button(
            label="â¬‡ êµ¬ì¡°í™”ëœ í‰ê°€ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (í…Œì´ë¸”í˜•)",
            data=csv_structured,
            file_name="qa_evaluation_structured.csv",
            mime="text/csv",
            key="structured_download"
        )
        st.download_button(
            label="â¬‡ GPT ì „ì²´ ì‘ë‹µ í¬í•¨ ì›ë³¸ ë‹¤ìš´ë¡œë“œ",
            data=csv_raw,
            file_name="qa_evaluation_raw.csv",
            mime="text/csv",
            key="raw_download"
        )
        
